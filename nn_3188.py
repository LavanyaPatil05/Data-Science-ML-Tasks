# -*- coding: utf-8 -*-
"""nn_3188.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/160iAabuvhURUwuA-POOR05PPisfq-bWA
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow import keras
from tensorflow.keras import layers

# Load your dataset
data = pd.read_csv('/content/crop_yield.csv')  # Adjust the filename as needed

# Preprocessing
# Convert categorical columns to numeric if necessary (e.g., one-hot encoding)
data = pd.get_dummies(data, columns=['Crop', 'Season', 'State'])

# Define features and target variable
X = data.drop(columns=['Yield'])
y = data['Yield']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Build the neural network model
model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    layers.Dense(64, activation='relu'),
    layers.Dense(1)  # Output layer for regression
])

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)

# Evaluate the model
loss = model.evaluate(X_test, y_test)
print(f'Test Loss: {loss}')

# Predicting crop yield
predictions = model.predict(X_test)

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler

# Assuming 'scaler' and 'model' have already been defined and trained

# Create a new input DataFrame
new_input_data = {
    'Crop': ['wheat'],         # Example crop
    'Crop_Year': [2023],      # Example year
    'Season': ['Rabi'],       # Example season
    'State': ['rajasthan'],      # Example state
    'Area': [100],            # Example area
    'Production': [500],      # Example production
    'Annual_Rainfall': [200], # Example rainfall
    'Fertilizer': [50],       # Example fertilizer usage
    'Pesticide': [10]         # Example pesticide usage
}

# Convert to DataFrame
new_input_df = pd.DataFrame(new_input_data)

# One-hot encode the categorical columns
new_input_df = pd.get_dummies(new_input_df, columns=['Crop', 'Season', 'State'])

# Ensure all columns match the training set
# If the training set had more categories, this will fill them with zeros
for column in X.columns:
    if column not in new_input_df.columns:
        new_input_df[column] = 0
new_input_df = new_input_df[X.columns]  # Reorder columns to match training data

# Standardize the new input features
new_input_scaled = scaler.transform(new_input_df)

# Predict the yield using the trained model
predicted_yield = model.predict(new_input_scaled)

# Output the prediction
print(f'Predicted Yield: {predicted_yield[0][0]}')